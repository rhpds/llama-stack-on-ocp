## Generate telemetry from Llamastack and vLLM

This assumes you have an observability stack running in OpenShift. To deploy the necessary components,
follow the [observability-hub guide](./README.md).

### vLLM

#### Metrics

For vLLM, metrics are generated by default and are exposed at `vllm-endpoint:port/metrics`. For a list of metrics,
you can `curl localhost:8000/metrics` from within a vLLM container.

#### Distributed Traces

It's possible to generate vLLM distributed trace data by updating the vLLM image and start command.
The [vLLM distributed tracing](./vllm-distributed-tracing.md) describes how to collect vLLM traces.

### Llamastack

With Llamastack, update the [configmap](../llama-stack/configmap.yaml) to enable telemetry collection with an opentelemetry receiver.
Follow the [observability-hub guide](./README.md) to install the `RH Build of OpenTelemetry Operator` and
`OpenTelemetryCollector`.

#### Updated manifests for telemetry trace collection with opentelemetry receiver endpoint

This is for traces only. There is a similar `otel_metric` sink and `otel_metric_endpoint`, however, there are currently
only 4 metrics generated within Llamastack, and these are duplicates of what vLLM provides.

[kubernetes/llama-stack/configmap.yaml](../llama-stack/configmap.yaml)

```yaml
---
      telemetry:
      - provider_id: meta-reference
        provider_type: inline::meta-reference
        config:
          service_name: ${env.OTEL_SERVICE_NAME:llama-stack}
          sinks: ${env.TELEMETRY_SINKS:console, otel_trace, sqlite} <-add otel_trace and/or otel_metric
          otel_trace_endpoint: ${env.OTEL_TRACE_ENDPOINT:} <-add ONLY if opentelemetry receiver endpoint is available.
---
```
And, in [kubernetes/llama-stack/deployment.yaml](../llama-stack/deployment.yaml)

```yaml
---
  template:
    metadata:
      labels:
        app: llama-stack
    spec:
      containers:
---
        env:
        - name: OTEL_SERVICE_NAME
          value: llamastack
        - name: OTEL_TRACE_ENDPOINT
          value: http://otel-collector.observability-hub.local.svc.cluster:4318/v1/traces
       #-  name: OTEL_METRIC_ENDPOINT
       #-  value: http://localhost:4318/v1/metrics
---
```

You can send to any in-cluster opentelemetry-collector by setting the
`OTEL_TRACE_ENDPOINT` to `http://service-name-otc.namespace-of-otc.svc.cluster.local:4318/v1/traces(or v1/metrics)`.

If collecting from multiple llamastack servers, opentelemetry-collector sidecars can be deployed
with each server deplyment. Below is a similar deployment.yaml snippet using opentelemetry sidecars.
In this example, each server would use `localhost` for the receiver endpoint, and the `opentelemetry-collector` would be
configured to export all telemetry to a central `opentelemetry-collector` where other various exporters would be configured
only once for all servers.

```yaml
---
  template:
    metadata:
      labels:
        app: llama-stack
      annotations:
        sidecar.opentelemetry.io/inject: llamastack-otelsidecar
    spec:
      containers:
---
        env:
        - name: OTEL_SERVICE_NAME
          value: llamastack
        - name: OTEL_TRACE_ENDPOINT
          value: http://localhost:4318/v1/traces
       #-  name: OTEL_METRIC_ENDPOINT
       #-  value: http://localhost:4318/v1/metrics
---
```

> **📝 NOTE:** Don't update the Llamastack deployment until _after_
> the [OpentelemetryCollector Sidecar](./otel-collector/otel-collector-llamastack-sidecar.yaml)
> and/or the [central OpenTelemetryCollector](./otel-collector/otel-collector.yaml) is deployed.
